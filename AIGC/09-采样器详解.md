# 第九章：采样器详解

采样器（Sampler/Scheduler）决定了扩散模型如何从噪声逐步生成图像。不同采样器在速度、质量、确定性等方面各有特点。

## 9.1 采样器概述

### 采样的本质

```
扩散模型的采样过程：

训练时：学习如何预测噪声 ε_θ(x_t, t)
采样时：用预测的噪声，从纯噪声逐步恢复数据

x_T (纯噪声) ──► x_{T-1} ──► ... ──► x_1 ──► x_0 (生成图像)
     │              │                    │
     └──────────────┴────────────────────┘
              采样器决定如何更新
```

### 采样器分类

```
┌─────────────────────────────────────────────────────────────┐
│                    采样器分类                               │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  1. 随机采样器 (Stochastic)                                │
│     ├── DDPM: 原始方法，每步加随机噪声                      │
│     ├── Ancestral samplers: 带"a"后缀的采样器              │
│     └── SDE solvers: 随机微分方程求解器                    │
│                                                             │
│  2. 确定性采样器 (Deterministic)                           │
│     ├── DDIM: 确定性版本，可减少步数                       │
│     ├── PLMS: 线性多步法                                   │
│     ├── DPM-Solver: 高阶ODE求解器                          │
│     ├── Euler: 一阶欧拉法                                  │
│     ├── Heun: 二阶Heun法                                   │
│     └── UniPC: 统一预测校正器                              │
│                                                             │
│  3. 特殊采样器                                             │
│     ├── LCM: 一致性模型采样                                │
│     ├── Turbo: 对抗蒸馏采样                                │
│     └── Flow Matching: 流匹配采样                          │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

## 9.2 DDPM采样器

### 理论基础

```
DDPM (Denoising Diffusion Probabilistic Models)

反向过程定义：
p_θ(x_{t-1} | x_t) = N(x_{t-1}; μ_θ(x_t, t), σ_t²·I)

其中：
μ_θ(x_t, t) = (1/√α_t) · (x_t - (β_t/√(1-ᾱ_t)) · ε_θ(x_t, t))
σ_t² = β_t  或  σ_t² = β̃_t = (1-ᾱ_{t-1})/(1-ᾱ_t) · β_t

采样公式：
x_{t-1} = μ_θ(x_t, t) + σ_t · z,  z ~ N(0, I)

关键：每步都要加随机噪声 z
```

### DDPM实现

```python
import torch
import torch.nn.functional as F
import numpy as np

class DDPMSampler:
    def __init__(self, num_timesteps=1000, beta_start=0.0001, beta_end=0.02):
        """
        DDPM采样器

        Args:
            num_timesteps: 总时间步数
            beta_start: β起始值
            beta_end: β结束值
        """
        self.num_timesteps = num_timesteps

        # 线性噪声调度
        self.betas = torch.linspace(beta_start, beta_end, num_timesteps)

        # 预计算常用值
        self.alphas = 1.0 - self.betas
        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)
        self.alphas_cumprod_prev = F.pad(self.alphas_cumprod[:-1], (1, 0), value=1.0)

        # 计算采样所需的系数
        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)
        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod)
        self.sqrt_recip_alphas = torch.sqrt(1.0 / self.alphas)

        # 后验方差
        self.posterior_variance = (
            self.betas * (1.0 - self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)
        )

    def _get_variance(self, t, variance_type="fixed_small"):
        """获取方差"""
        if variance_type == "fixed_small":
            # σ_t² = β̃_t (更稳定)
            return self.posterior_variance[t]
        elif variance_type == "fixed_large":
            # σ_t² = β_t
            return self.betas[t]
        else:
            raise ValueError(f"Unknown variance type: {variance_type}")

    @torch.no_grad()
    def step(self, model_output, t, x_t, generator=None):
        """
        单步采样

        Args:
            model_output: 模型预测的噪声 ε_θ(x_t, t)
            t: 当前时间步
            x_t: 当前状态
            generator: 随机数生成器

        Returns:
            x_{t-1}: 上一时间步的状态
        """
        # 获取系数
        alpha_t = self.alphas[t]
        alpha_cumprod_t = self.alphas_cumprod[t]
        beta_t = self.betas[t]
        sqrt_one_minus_alpha_cumprod_t = self.sqrt_one_minus_alphas_cumprod[t]
        sqrt_recip_alpha_t = self.sqrt_recip_alphas[t]

        # 计算均值 μ_θ
        # μ = (1/√α_t) · (x_t - (β_t/√(1-ᾱ_t)) · ε_θ)
        pred_mean = sqrt_recip_alpha_t * (
            x_t - beta_t / sqrt_one_minus_alpha_cumprod_t * model_output
        )

        if t > 0:
            # 获取方差并采样噪声
            variance = self._get_variance(t)
            noise = torch.randn_like(x_t, generator=generator)

            # x_{t-1} = μ + σ·z
            x_prev = pred_mean + torch.sqrt(variance) * noise
        else:
            # 最后一步不加噪声
            x_prev = pred_mean

        return x_prev

    @torch.no_grad()
    def sample(self, model, shape, device='cuda', verbose=True):
        """
        完整采样过程

        Args:
            model: 噪声预测模型
            shape: 输出形状 (B, C, H, W)
            device: 设备

        Returns:
            生成的样本
        """
        # 从纯噪声开始
        x = torch.randn(shape, device=device)

        # 逐步去噪 (从T到0)
        for t in reversed(range(self.num_timesteps)):
            if verbose and t % 100 == 0:
                print(f"Sampling step {self.num_timesteps - t}/{self.num_timesteps}")

            t_tensor = torch.full((shape[0],), t, device=device, dtype=torch.long)

            # 预测噪声
            noise_pred = model(x, t_tensor)

            # 采样x_{t-1}
            x = self.step(noise_pred, t, x)

        return x
```

### DDPM特点

```
优点：
✓ 理论完备，基于变分推断
✓ 生成质量高
✓ 训练稳定

缺点：
✗ 需要1000步采样，非常慢
✗ 每步都加随机噪声，结果不确定
✗ 无法减少步数（强行减少会严重降质）
```

---

## 9.3 DDIM采样器

### 理论基础

```
DDIM (Denoising Diffusion Implicit Models)

核心发现：可以定义一族非马尔可夫过程，都对应同一个边际分布

DDIM采样公式：
x_{t-1} = √ᾱ_{t-1} · x̂_0 + √(1-ᾱ_{t-1}-σ_t²) · ε_θ(x_t, t) + σ_t · z

其中 x̂_0 是预测的原始图像：
x̂_0 = (x_t - √(1-ᾱ_t) · ε_θ(x_t, t)) / √ᾱ_t

σ_t 控制随机性：
- σ_t = 0: 完全确定性 (DDIM)
- σ_t = √((1-ᾱ_{t-1})/(1-ᾱ_t)) · √(1-ᾱ_t/ᾱ_{t-1}): 等价于DDPM

参数 η ∈ [0, 1] 控制：
σ_t = η · √((1-ᾱ_{t-1})/(1-ᾱ_t)) · √(1-ᾱ_t/ᾱ_{t-1})

η = 0: DDIM (确定性)
η = 1: DDPM (随机性)
```

### DDIM实现

```python
class DDIMSampler:
    def __init__(self, num_train_timesteps=1000, beta_start=0.0001, beta_end=0.02):
        """
        DDIM采样器
        """
        self.num_train_timesteps = num_train_timesteps

        # 噪声调度
        self.betas = torch.linspace(beta_start, beta_end, num_train_timesteps)
        self.alphas = 1.0 - self.betas
        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)

    def set_timesteps(self, num_inference_steps):
        """
        设置推理步数（可以远小于训练步数）

        Args:
            num_inference_steps: 推理步数 (如20, 50)
        """
        self.num_inference_steps = num_inference_steps

        # 均匀选择时间步
        step_ratio = self.num_train_timesteps // num_inference_steps
        self.timesteps = (
            (np.arange(0, num_inference_steps) * step_ratio)
            .round()[::-1]
            .copy()
            .astype(np.int64)
        )
        self.timesteps = torch.from_numpy(self.timesteps)

    @torch.no_grad()
    def step(self, model_output, t, x_t, eta=0.0, generator=None):
        """
        DDIM单步采样

        Args:
            model_output: 预测的噪声 ε_θ
            t: 当前时间步
            x_t: 当前状态
            eta: 随机性参数 (0=确定性, 1=DDPM)
        """
        # 获取时间步索引
        t_idx = (self.timesteps == t).nonzero(as_tuple=True)[0]
        prev_t = self.timesteps[t_idx + 1] if t_idx + 1 < len(self.timesteps) else 0

        # 获取α值
        alpha_cumprod_t = self.alphas_cumprod[t]
        alpha_cumprod_prev = self.alphas_cumprod[prev_t] if prev_t > 0 else torch.tensor(1.0)

        # 1. 预测x_0
        # x̂_0 = (x_t - √(1-ᾱ_t) · ε) / √ᾱ_t
        pred_x0 = (x_t - torch.sqrt(1 - alpha_cumprod_t) * model_output) / torch.sqrt(alpha_cumprod_t)

        # 可选：裁剪x_0到[-1, 1]
        pred_x0 = torch.clamp(pred_x0, -1, 1)

        # 2. 计算方差
        # σ_t = η · √((1-ᾱ_{t-1})/(1-ᾱ_t)) · √(1-ᾱ_t/ᾱ_{t-1})
        variance = (1 - alpha_cumprod_prev) / (1 - alpha_cumprod_t) * (1 - alpha_cumprod_t / alpha_cumprod_prev)
        std = eta * torch.sqrt(variance)

        # 3. 计算"方向"指向x_t
        # 这是确定性部分的系数
        pred_dir = torch.sqrt(1 - alpha_cumprod_prev - std**2) * model_output

        # 4. 组合得到x_{t-1}
        # x_{t-1} = √ᾱ_{t-1} · x̂_0 + √(1-ᾱ_{t-1}-σ²) · ε + σ · z
        x_prev = torch.sqrt(alpha_cumprod_prev) * pred_x0 + pred_dir

        if eta > 0 and prev_t > 0:
            noise = torch.randn_like(x_t, generator=generator)
            x_prev = x_prev + std * noise

        return x_prev, pred_x0

    @torch.no_grad()
    def sample(self, model, shape, num_inference_steps=50, eta=0.0,
               device='cuda', verbose=True):
        """
        完整采样

        Args:
            num_inference_steps: 推理步数
            eta: 随机性 (0=DDIM, 1=DDPM)
        """
        self.set_timesteps(num_inference_steps)

        # 从噪声开始
        x = torch.randn(shape, device=device)

        for i, t in enumerate(self.timesteps):
            if verbose:
                print(f"Step {i+1}/{num_inference_steps}, t={t}")

            t_tensor = torch.full((shape[0],), t, device=device, dtype=torch.long)

            # 预测噪声
            noise_pred = model(x, t_tensor)

            # DDIM步
            x, pred_x0 = self.step(noise_pred, t, x, eta=eta)

        return x
```

### DDIM vs DDPM 直观理解

```
DDPM采样路径（随机）：
────────────────────────────────────────────────────────
x_T ●───╲
         ╲──●───╲
                 ╲──●───╲
                         ╲──●───╲
                                 ╲──● x_0
每步都有随机扰动，路径弯曲


DDIM采样路径（确定性，η=0）：
────────────────────────────────────────────────────────
x_T ●─────────●─────────●─────────●─────────● x_0

直接沿着"最优"方向前进，路径是直的
相同的x_T总是得到相同的x_0
```

### DDIM的优势

```
1. 可以减少步数
   - DDPM: 需要1000步
   - DDIM: 20-50步即可达到类似质量

2. 确定性生成
   - 相同的噪声 → 相同的输出
   - 便于调试和复现

3. 可调随机性
   - η=0: 完全确定性
   - 0<η<1: 部分随机性
   - η=1: 等价于DDPM

4. 支持插值
   - 在潜空间中插值两个噪声
   - 生成平滑过渡的图像
```

---

## 9.4 采样器数学统一视角

### SDE与ODE视角

```
扩散模型可以用SDE（随机微分方程）描述：

前向SDE：
dx = f(x,t)dt + g(t)dw

其中 dw 是维纳过程（布朗运动）

反向SDE：
dx = [f(x,t) - g(t)² ∇_x log p_t(x)] dt + g(t) dw̄

关键发现：存在对应的ODE，有相同的边际分布：

概率流ODE：
dx = [f(x,t) - ½g(t)² ∇_x log p_t(x)] dt

DDPM ≈ 离散化反向SDE
DDIM ≈ 离散化概率流ODE
```

### 不同采样器的统一框架

```python
class UnifiedSampler:
    """
    统一采样器框架

    所有采样器都可以表示为：
    x_{t-1} = a(t) · x̂_0 + b(t) · ε_θ + c(t) · z

    其中 z ~ N(0, I) 是随机噪声
    """

    def step(self, x_t, t, noise_pred, sampler_type='ddim', eta=0.0):
        # 预测x_0
        pred_x0 = self.predict_x0(x_t, t, noise_pred)

        if sampler_type == 'ddpm':
            # DDPM: 固定方差的随机采样
            return self.ddpm_step(x_t, t, noise_pred, pred_x0)

        elif sampler_type == 'ddim':
            # DDIM: 可控随机性
            return self.ddim_step(x_t, t, noise_pred, pred_x0, eta)

        elif sampler_type == 'euler':
            # Euler: 一阶ODE求解
            return self.euler_step(x_t, t, noise_pred, pred_x0)

        elif sampler_type == 'heun':
            # Heun: 二阶ODE求解
            return self.heun_step(x_t, t, noise_pred, pred_x0)
```

---

## 9.5 Euler采样器

### 原理

```
Euler方法：最简单的ODE数值求解方法

概率流ODE：
dx/dt = f_θ(x, t)

Euler离散化：
x_{t-Δt} = x_t + f_θ(x_t, t) · (-Δt)

对于扩散模型：
f_θ(x_t, t) 可以从噪声预测 ε_θ 转换得到
```

### 实现

```python
class EulerSampler:
    def __init__(self, num_train_timesteps=1000, beta_start=0.0001, beta_end=0.02):
        self.num_train_timesteps = num_train_timesteps
        self.betas = torch.linspace(beta_start, beta_end, num_train_timesteps)
        self.alphas = 1.0 - self.betas
        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)

        # 计算sigma (用于将离散时间映射到连续时间)
        self.sigmas = ((1 - self.alphas_cumprod) / self.alphas_cumprod).sqrt()

    def set_timesteps(self, num_inference_steps):
        # 在sigma空间均匀采样
        sigmas = np.linspace(self.sigmas[-1].item(), self.sigmas[0].item(), num_inference_steps)
        self.sigmas_schedule = torch.from_numpy(sigmas)

        # 找到对应的时间步
        self.timesteps = self._sigma_to_t(self.sigmas_schedule)

    @torch.no_grad()
    def step(self, model_output, t_idx, x_t):
        """
        Euler步
        """
        sigma = self.sigmas_schedule[t_idx]
        sigma_next = self.sigmas_schedule[t_idx + 1] if t_idx + 1 < len(self.sigmas_schedule) else 0

        # 将噪声预测转换为x_0预测
        # x_0 = x_t - sigma * ε
        pred_x0 = x_t - sigma * model_output

        # 计算导数 (denoised - x) / sigma
        derivative = (x_t - pred_x0) / sigma

        # Euler更新
        dt = sigma_next - sigma
        x_next = x_t + derivative * dt

        return x_next


class EulerAncestralSampler(EulerSampler):
    """
    Euler Ancestral: 带随机噪声的Euler采样器

    在每步添加少量噪声，增加多样性
    """
    @torch.no_grad()
    def step(self, model_output, t_idx, x_t, eta=1.0):
        sigma = self.sigmas_schedule[t_idx]
        sigma_next = self.sigmas_schedule[t_idx + 1] if t_idx + 1 < len(self.sigmas_schedule) else 0

        # 预测x_0
        pred_x0 = x_t - sigma * model_output

        # 计算噪声量
        sigma_up = min(sigma_next, (sigma_next**2 * (sigma**2 - sigma_next**2) / sigma**2).sqrt())
        sigma_up = eta * sigma_up

        sigma_down = (sigma_next**2 - sigma_up**2).sqrt()

        # 确定性部分
        derivative = (x_t - pred_x0) / sigma
        x_next = x_t + derivative * (sigma_down - sigma)

        # 随机部分
        if sigma_next > 0:
            noise = torch.randn_like(x_t)
            x_next = x_next + noise * sigma_up

        return x_next
```

---

## 9.6 Heun采样器

### 原理

```
Heun方法（改进的Euler，二阶精度）

步骤：
1. 先用Euler预测一步：x̃ = x_t + f(x_t, t) · Δt
2. 用预测点的导数校正：x_{t+Δt} = x_t + ½[f(x_t, t) + f(x̃, t+Δt)] · Δt

相当于用梯形面积代替矩形面积，更准确

       f(x̃,t+Δt)
          ╱│
         ╱ │
        ╱  │
       ╱   │
      ╱    │
f(x_t,t)───┘
      │    │
      └────┘
        Δt

Euler: 只用左边的高度
Heun: 用左右高度的平均
```

### 实现

```python
class HeunSampler:
    """
    Heun采样器（二阶）

    比Euler更准确，但每步需要2次模型调用
    """
    def __init__(self, num_train_timesteps=1000):
        # ... 初始化同Euler
        pass

    @torch.no_grad()
    def step(self, model, t_idx, x_t):
        """
        Heun步（需要model而不只是model_output，因为要调用两次）
        """
        sigma = self.sigmas_schedule[t_idx]
        sigma_next = self.sigmas_schedule[t_idx + 1] if t_idx + 1 < len(self.sigmas_schedule) else 0

        t = self.timesteps[t_idx]
        t_next = self.timesteps[t_idx + 1] if t_idx + 1 < len(self.timesteps) else 0

        # 第一次预测
        noise_pred_1 = model(x_t, t)
        d_1 = (x_t - (x_t - sigma * noise_pred_1)) / sigma  # 导数

        # Euler预测
        x_euler = x_t + d_1 * (sigma_next - sigma)

        if sigma_next == 0:
            return x_euler

        # 第二次预测（在Euler预测点）
        noise_pred_2 = model(x_euler, t_next)
        d_2 = (x_euler - (x_euler - sigma_next * noise_pred_2)) / sigma_next

        # Heun校正：用两个导数的平均
        x_next = x_t + (d_1 + d_2) / 2 * (sigma_next - sigma)

        return x_next
```

---

## 9.7 DPM-Solver

### 原理

```
DPM-Solver: 专门为扩散模型设计的高阶ODE求解器

核心思想：
1. 将扩散ODE改写为关于log(σ)的形式
2. 使用高阶多步法求解
3. 利用之前步的噪声预测，减少模型调用

DPM-Solver++（改进版）：
- 更好的数值稳定性
- 支持更少步数（10-25步）
```

### DPM-Solver++实现

```python
class DPMSolverPlusPlus:
    """
    DPM-Solver++采样器

    支持1阶、2阶、3阶求解器
    """
    def __init__(self, num_train_timesteps=1000, beta_start=0.0001, beta_end=0.02):
        self.num_train_timesteps = num_train_timesteps
        self.betas = torch.linspace(beta_start, beta_end, num_train_timesteps)
        self.alphas = 1.0 - self.betas
        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)

        # λ_t = log(α_t) - log(σ_t)
        self.lambda_t = torch.log(self.alphas_cumprod.sqrt()) - torch.log((1 - self.alphas_cumprod).sqrt())

    def set_timesteps(self, num_inference_steps, order=2):
        """
        设置时间步

        Args:
            order: 求解器阶数 (1, 2, 3)
        """
        self.order = order
        self.num_inference_steps = num_inference_steps

        # 在λ空间均匀采样
        lambda_min = self.lambda_t[-1]
        lambda_max = self.lambda_t[0]
        lambdas = torch.linspace(lambda_max, lambda_min, num_inference_steps + 1)

        # 转换回时间步
        self.timesteps = self._lambda_to_t(lambdas)

        # 存储之前的噪声预测（用于多步法）
        self.model_outputs = []

    @torch.no_grad()
    def step(self, model_output, t_idx, x_t):
        """
        DPM-Solver++步
        """
        # 存储当前预测
        self.model_outputs.append(model_output)
        if len(self.model_outputs) > self.order:
            self.model_outputs.pop(0)

        t = self.timesteps[t_idx]
        t_next = self.timesteps[t_idx + 1] if t_idx + 1 < len(self.timesteps) else 0

        # 根据可用的历史预测选择阶数
        current_order = min(self.order, len(self.model_outputs))

        if current_order == 1:
            return self._first_order_step(x_t, t, t_next, model_output)
        elif current_order == 2:
            return self._second_order_step(x_t, t, t_next)
        else:
            return self._third_order_step(x_t, t, t_next)

    def _first_order_step(self, x_t, t, t_next, noise_pred):
        """一阶步（类似DDIM）"""
        alpha_t = self.alphas_cumprod[t]
        alpha_next = self.alphas_cumprod[t_next] if t_next > 0 else torch.tensor(1.0)
        sigma_t = (1 - alpha_t).sqrt()
        sigma_next = (1 - alpha_next).sqrt()

        # 预测x_0
        pred_x0 = (x_t - sigma_t * noise_pred) / alpha_t.sqrt()

        # 计算x_{t-1}
        x_next = alpha_next.sqrt() * pred_x0 + sigma_next * noise_pred

        return x_next

    def _second_order_step(self, x_t, t, t_next):
        """二阶步（使用两个噪声预测）"""
        # ... 使用self.model_outputs[-2:]进行二阶更新
        # 具体公式参见DPM-Solver论文
        pass

    def _third_order_step(self, x_t, t, t_next):
        """三阶步（使用三个噪声预测）"""
        # ... 使用self.model_outputs[-3:]进行三阶更新
        pass
```

---

## 9.8 采样器对比

### 性能对比表

```
┌──────────────────┬────────┬────────┬────────┬────────┬──────────┐
│     采样器       │ 步数   │ 质量   │ 速度   │ 随机性 │ 适用场景 │
├──────────────────┼────────┼────────┼────────┼────────┼──────────┤
│ DDPM             │ 1000   │ ★★★★★ │ ★      │ 高     │ 基准参考 │
├──────────────────┼────────┼────────┼────────┼────────┼──────────┤
│ DDIM             │ 20-50  │ ★★★★  │ ★★★★  │ 可调   │ 通用     │
├──────────────────┼────────┼────────┼────────┼────────┼──────────┤
│ Euler            │ 20-50  │ ★★★   │ ★★★★★ │ 无     │ 快速预览 │
├──────────────────┼────────┼────────┼────────┼────────┼──────────┤
│ Euler Ancestral  │ 20-50  │ ★★★★  │ ★★★★  │ 高     │ 多样性   │
├──────────────────┼────────┼────────┼────────┼────────┼──────────┤
│ Heun             │ 20-50  │ ★★★★  │ ★★★   │ 无     │ 高质量   │
├──────────────────┼────────┼────────┼────────┼────────┼──────────┤
│ DPM-Solver++     │ 15-25  │ ★★★★★ │ ★★★★  │ 无     │ 推荐使用 │
├──────────────────┼────────┼────────┼────────┼────────┼──────────┤
│ DPM++ 2M Karras  │ 15-25  │ ★★★★★ │ ★★★★  │ 无     │ SD推荐   │
├──────────────────┼────────┼────────┼────────┼────────┼──────────┤
│ UniPC            │ 10-20  │ ★★★★★ │ ★★★★★ │ 无     │ 极速高质 │
├──────────────────┼────────┼────────┼────────┼────────┼──────────┤
│ LCM              │ 4-8    │ ★★★★  │ ★★★★★ │ 低     │ 实时应用 │
└──────────────────┴────────┴────────┴────────┴────────┴──────────┘
```

### 选择建议

```
1. 日常使用（质量与速度平衡）
   推荐：DPM++ 2M Karras, 20-30步

2. 追求最高质量
   推荐：DPM++ SDE Karras 或 Heun, 30-50步

3. 快速预览
   推荐：Euler 或 LCM, 10-20步

4. 需要多样性/创意
   推荐：Euler Ancestral 或 DPM++ 2S Ancestral

5. 实时应用
   推荐：LCM 或 Turbo, 4-8步

6. 精确复现
   推荐：DDIM (eta=0) 或任何确定性采样器
```

---

## 9.9 噪声调度

### 常见调度方式

```python
def get_beta_schedule(schedule_type, num_timesteps, beta_start=0.0001, beta_end=0.02):
    """
    不同的噪声调度方式
    """
    if schedule_type == "linear":
        # 线性调度（DDPM原始）
        return torch.linspace(beta_start, beta_end, num_timesteps)

    elif schedule_type == "scaled_linear":
        # 缩放线性（Stable Diffusion使用）
        return torch.linspace(beta_start**0.5, beta_end**0.5, num_timesteps) ** 2

    elif schedule_type == "cosine":
        # 余弦调度（更平滑，适合小图像）
        steps = num_timesteps + 1
        s = 0.008
        t = torch.linspace(0, num_timesteps, steps)
        alphas_cumprod = torch.cos((t / num_timesteps + s) / (1 + s) * torch.pi / 2) ** 2
        alphas_cumprod = alphas_cumprod / alphas_cumprod[0]
        betas = 1 - alphas_cumprod[1:] / alphas_cumprod[:-1]
        return torch.clamp(betas, 0.0001, 0.9999)

    elif schedule_type == "squaredcos_cap_v2":
        # 改进的余弦调度（SDXL使用）
        # ...
        pass
```

### Karras噪声调度

```python
def get_sigmas_karras(n, sigma_min, sigma_max, rho=7.0):
    """
    Karras等人提出的sigma调度
    在sigma空间更均匀，适合高阶求解器

    σᵢ = (σ_max^(1/ρ) + i/(n-1) · (σ_min^(1/ρ) - σ_max^(1/ρ)))^ρ
    """
    ramp = torch.linspace(0, 1, n)
    min_inv_rho = sigma_min ** (1 / rho)
    max_inv_rho = sigma_max ** (1 / rho)
    sigmas = (max_inv_rho + ramp * (min_inv_rho - max_inv_rho)) ** rho
    return sigmas
```

---

## 9.10 实践代码：使用diffusers

```python
from diffusers import StableDiffusionPipeline
from diffusers import (
    DDPMScheduler,
    DDIMScheduler,
    EulerDiscreteScheduler,
    EulerAncestralDiscreteScheduler,
    HeunDiscreteScheduler,
    DPMSolverMultistepScheduler,
    UniPCMultistepScheduler,
    LCMScheduler,
)

# 加载模型
pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16
).to("cuda")

prompt = "a beautiful landscape, oil painting"

# 使用不同采样器生成
schedulers = {
    "DDPM": DDPMScheduler.from_config(pipe.scheduler.config),
    "DDIM": DDIMScheduler.from_config(pipe.scheduler.config),
    "Euler": EulerDiscreteScheduler.from_config(pipe.scheduler.config),
    "Euler A": EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config),
    "Heun": HeunDiscreteScheduler.from_config(pipe.scheduler.config),
    "DPM++ 2M": DPMSolverMultistepScheduler.from_config(pipe.scheduler.config),
    "DPM++ 2M Karras": DPMSolverMultistepScheduler.from_config(
        pipe.scheduler.config,
        use_karras_sigmas=True
    ),
    "UniPC": UniPCMultistepScheduler.from_config(pipe.scheduler.config),
}

results = {}
for name, scheduler in schedulers.items():
    pipe.scheduler = scheduler

    # 设置相同的随机种子
    generator = torch.Generator("cuda").manual_seed(42)

    # 根据采样器调整步数
    if name == "DDPM":
        steps = 1000
    elif name in ["DPM++ 2M", "DPM++ 2M Karras", "UniPC"]:
        steps = 20
    else:
        steps = 30

    image = pipe(
        prompt,
        num_inference_steps=steps,
        generator=generator
    ).images[0]

    results[name] = image
    print(f"{name}: {steps} steps")
```

---

## 总结

### 关键公式对比

```
┌────────────────────────────────────────────────────────────────┐
│                      采样器核心公式                            │
├────────────────────────────────────────────────────────────────┤
│                                                                │
│  DDPM:                                                         │
│  x_{t-1} = (1/√α_t)(x_t - β_t/√(1-ᾱ_t)·ε_θ) + σ_t·z          │
│                                                                │
│  DDIM:                                                         │
│  x_{t-1} = √ᾱ_{t-1}·x̂_0 + √(1-ᾱ_{t-1}-σ²)·ε_θ + σ·z         │
│  其中 x̂_0 = (x_t - √(1-ᾱ_t)·ε_θ) / √ᾱ_t                      │
│                                                                │
│  Euler:                                                        │
│  x_{t-Δt} = x_t + (x_t - x̂_0)/σ_t · Δσ                        │
│                                                                │
│  Heun (校正步):                                                │
│  x_{t-Δt} = x_t + ½(d_1 + d_2) · Δσ                           │
│                                                                │
└────────────────────────────────────────────────────────────────┘
```

### 学习重点

```
1. 理解DDPM与DDIM的核心区别
   - DDPM: 随机采样，理论严格
   - DDIM: 确定性采样，可加速

2. 掌握SDE/ODE视角
   - 扩散模型本质是求解微分方程
   - 不同采样器 = 不同数值求解方法

3. 实践中的选择
   - DPM++ 2M Karras 是当前最佳默认选择
   - 根据需求调整步数和采样器类型

4. 噪声调度的影响
   - Karras调度通常更好
   - 不同模型可能需要不同调度
```
