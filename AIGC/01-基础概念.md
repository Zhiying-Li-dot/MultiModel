# 第一章：基础概念

## 1.1 什么是AIGC

### 定义

**AIGC (AI Generated Content)** 是指利用人工智能技术自动生成内容的技术，包括文本、图像、音频、视频、3D模型等多种形式。

```
内容生成方式演进：

PGC (Professional Generated Content)
 │  专业人员创作
 ↓
UGC (User Generated Content)
 │  普通用户创作
 ↓
AIGC (AI Generated Content)
    AI自动生成
```

### AIGC vs 传统AI

| 维度 | 传统AI | AIGC |
|------|--------|------|
| 任务类型 | 判别式（分类、检测） | 生成式（创造新内容） |
| 输出 | 类别、标签、数值 | 图像、文本、音频等 |
| 典型模型 | CNN、ResNet | GAN、Diffusion、GPT |
| 评估方式 | 准确率、F1 | FID、IS、人类评估 |

---

## 1.2 生成模型分类

### 四大生成范式

```
生成模型
├── 1. GAN (生成对抗网络)
│   ├── 原理：生成器 vs 判别器的博弈
│   ├── 优点：生成质量高、速度快
│   └── 缺点：训练不稳定、模式崩塌
│
├── 2. VAE (变分自编码器)
│   ├── 原理：编码-解码 + 隐空间正则化
│   ├── 优点：训练稳定、隐空间可解释
│   └── 缺点：生成图像偏模糊
│
├── 3. Diffusion (扩散模型)
│   ├── 原理：逐步加噪→逐步去噪
│   ├── 优点：生成质量最高、多样性好
│   └── 缺点：采样速度慢
│
├── 4. Autoregressive (自回归模型)
│   ├── 原理：逐token预测下一个
│   ├── 优点：自然语言生成效果好
│   └── 缺点：无法并行生成
│
└── 5. Flow-based (流模型)
    ├── 原理：可逆变换
    ├── 优点：精确的似然计算
    └── 缺点：模型设计受限
```

### 模型对比

| 模型 | 代表作品 | 适用场景 |
|------|----------|----------|
| GAN | StyleGAN、BigGAN | 人脸生成、图像编辑 |
| VAE | VQ-VAE、DALL-E 1 | 图像压缩、特征学习 |
| Diffusion | Stable Diffusion、DALL-E 2/3 | 文生图、图像编辑 |
| Autoregressive | GPT、LLaMA | 文本生成、代码生成 |
| Flow | Glow、RealNVP | 图像生成、密度估计 |

---

## 1.3 发展历史

### 里程碑时间线

```
2014 ─── GAN诞生 (Goodfellow)
  │      生成对抗网络开创生成模型新范式
  │
2015 ─── DCGAN
  │      将CNN引入GAN，稳定训练
  │
2017 ─── Transformer (Attention Is All You Need)
  │      注意力机制革命
  │      VAE-GAN、WGAN等改进
  │
2018 ─── GPT-1、BERT
  │      大规模预训练语言模型
  │      StyleGAN (高质量人脸生成)
  │
2019 ─── GPT-2
  │      展示大模型涌现能力
  │      VQ-VAE-2
  │
2020 ─── GPT-3 (175B参数)
  │      大语言模型时代开启
  │      DDPM (去噪扩散概率模型)
  │
2021 ─── DALL-E 1、CLIP
  │      文本到图像生成突破
  │      Codex (代码生成)
  │
2022 ─── Stable Diffusion开源 ⭐
  │      DALL-E 2、Midjourney
  │      ChatGPT发布 (GPT-3.5)
  │
2023 ─── GPT-4 (多模态)
  │      Midjourney V5
  │      SDXL、SVD
  │
2024 ─── Sora (文生视频)
  │      Stable Diffusion 3
  │      Claude 3、Gemini
  │
2025 ─── 多模态统一模型
         实时视频生成
         3D生成成熟
```

### 关键突破

| 年份 | 突破 | 影响 |
|------|------|------|
| 2014 | GAN | 开创对抗训练范式 |
| 2017 | Transformer | 注意力机制成为基础架构 |
| 2020 | DDPM | 扩散模型超越GAN |
| 2021 | CLIP | 图文对齐，零样本能力 |
| 2022 | Stable Diffusion | 开源推动AIGC普及 |
| 2022 | ChatGPT | AI应用破圈 |
| 2024 | Sora | 视频生成新高度 |

---

## 1.4 核心概念

### 隐空间 (Latent Space)

```
高维数据空间                    低维隐空间
(如 512x512 图像)              (如 64x64x4)
      │                            │
      │   ┌─────────────┐          │
      └──►│   Encoder   │──────────┘
          └─────────────┘
                               可以在隐空间中：
      ┌─────────────┐          - 插值生成
      │   Decoder   │◄─────────- 属性编辑
      └─────────────┘          - 随机采样
            │
            ▼
        生成图像
```

**为什么需要隐空间？**
1. 降低计算复杂度
2. 去除冗余信息
3. 学习数据的本质特征
4. 便于操控和编辑

### 条件生成

```python
# 无条件生成
z = torch.randn(1, latent_dim)  # 随机噪声
image = generator(z)

# 条件生成
z = torch.randn(1, latent_dim)
condition = text_encoder("a cat sitting on a sofa")  # 文本条件
image = generator(z, condition)
```

条件类型：
- **文本条件**: Text-to-Image (DALL-E, SD)
- **图像条件**: Image-to-Image (Pix2Pix, ControlNet)
- **类别条件**: Class-conditional (BigGAN)
- **其他条件**: 边缘图、深度图、姿态等

### 采样与推理

```
训练 (Training)           推理/采样 (Inference/Sampling)
    │                          │
学习数据分布 P(x)          从分布中生成样本
    │                          │
    ▼                          ▼
优化模型参数              输入噪声 → 生成图像
```

---

## 1.5 评估指标

### 图像生成指标

| 指标 | 全称 | 含义 | 越小/大越好 |
|------|------|------|-------------|
| **FID** | Fréchet Inception Distance | 生成图像与真实图像分布距离 | 越小越好 |
| **IS** | Inception Score | 生成图像质量与多样性 | 越大越好 |
| **CLIP Score** | - | 图文匹配程度 | 越大越好 |
| **LPIPS** | Learned Perceptual Image Patch Similarity | 感知相似度 | 越小越好 |

### FID计算原理

```python
def calculate_fid(real_images, generated_images):
    """
    FID = ||μ_r - μ_g||² + Tr(Σ_r + Σ_g - 2(Σ_r·Σ_g)^0.5)

    使用预训练的Inception网络提取特征
    """
    # 1. 提取真实图像特征
    real_features = inception(real_images)
    mu_r, sigma_r = real_features.mean(0), cov(real_features)

    # 2. 提取生成图像特征
    gen_features = inception(generated_images)
    mu_g, sigma_g = gen_features.mean(0), cov(gen_features)

    # 3. 计算FID
    diff = mu_r - mu_g
    covmean = sqrtm(sigma_r @ sigma_g)
    fid = diff @ diff + np.trace(sigma_r + sigma_g - 2 * covmean)

    return fid
```

### 文本生成指标

| 指标 | 含义 |
|------|------|
| **Perplexity** | 困惑度，语言模型不确定性 |
| **BLEU** | 机器翻译质量 |
| **ROUGE** | 摘要质量 |
| **Human Eval** | 人类评估（最可靠） |

---

## 总结

| 概念 | 要点 |
|------|------|
| AIGC定义 | AI自动生成内容的技术 |
| 生成范式 | GAN、VAE、Diffusion、Autoregressive、Flow |
| 当前主流 | Diffusion (图像)、Transformer (文本) |
| 隐空间 | 低维表示，便于操控 |
| 评估指标 | FID (图像)、Perplexity (文本) |
