# 第五章：数据工程

数据是多模态模型成功的关键因素之一。本章介绍预训练数据、指令数据构建和数据质量控制。

## 5.1 预训练数据

### 主要数据集

| 数据集 | 规模 | 来源 | 特点 |
|--------|------|------|------|
| **LAION-5B** | 50亿对 | 网络爬取 | 规模最大，噪声较多 |
| **LAION-400M** | 4亿对 | LAION子集 | CLIP训练用 |
| **CC3M** | 300万对 | Conceptual Captions | 质量较高 |
| **CC12M** | 1200万对 | CC扩展版 | 中等规模 |
| **DataComp** | 多规模 | 研究用 | 有多种规模版本 |
| **WebLI** | 100亿对 | Google内部 | PaLI系列使用 |
| **COYO-700M** | 7亿对 | 韩国团队 | 开源可用 |

### 数据格式示例

```json
{
  "image_url": "https://example.com/images/dog_park.jpg",
  "caption": "A golden retriever playing fetch in the park on a sunny day",
  "width": 1024,
  "height": 768,
  "clip_score": 0.32,
  "language": "en"
}
```

### LAION数据处理流程

```
互联网图片
     │
     ▼
┌─────────────────────────────────┐
│ 1. Common Crawl网页爬取          │
│    提取<img>标签和alt文本        │
└─────────────────┬───────────────┘
                  ▼
┌─────────────────────────────────┐
│ 2. 基础过滤                      │
│    - 图片可访问性检查            │
│    - 尺寸过滤 (>256px)          │
│    - 文本长度过滤 (>5 words)     │
└─────────────────┬───────────────┘
                  ▼
┌─────────────────────────────────┐
│ 3. CLIP分数计算                  │
│    计算图文相似度                │
│    保留score > 0.28             │
└─────────────────┬───────────────┘
                  ▼
┌─────────────────────────────────┐
│ 4. 安全过滤                      │
│    - NSFW检测                    │
│    - 版权内容过滤                │
│    - 人脸过滤（可选）            │
└─────────────────┬───────────────┘
                  ▼
        LAION数据集
```

---

## 5.2 指令数据构建

### 方法1: GPT辅助生成（LLaVA方式）

这是最常用的高质量指令数据构建方法。

#### 流程

```
┌─────────────────────────────────────────────────┐
│                GPT辅助数据生成                   │
├─────────────────────────────────────────────────┤
│                                                 │
│  输入：                                         │
│  ├─ 图像（或图像描述）                           │
│  ├─ 边界框标注（可选）                           │
│  └─ 场景描述                                    │
│                                                 │
│                    ↓                            │
│                                                 │
│  GPT-4 Prompt：                                 │
│  "给定以下图像信息：                             │
│   - 场景：公园，阳光明媚                         │
│   - 物体：一只金毛犬(bbox: [100,200,300,400])   │
│   - 动作：在草地上奔跑                           │
│                                                 │
│   请生成3种类型的问答对：                        │
│   1. 描述性问题                                 │
│   2. 推理性问题                                 │
│   3. 细节性问题"                                │
│                                                 │
│                    ↓                            │
│                                                 │
│  GPT-4 输出：                                   │
│  Q1: 描述一下这张图片的内容                      │
│  A1: 这张图片展示了一只金毛犬在阳光明媚的         │
│      公园里快乐地奔跑...                         │
│                                                 │
│  Q2: 这只狗看起来心情如何？为什么？              │
│  A2: 这只狗看起来非常开心和兴奋。从它张开的       │
│      嘴巴、飘动的毛发和轻快的步伐可以看出...     │
│                                                 │
│  Q3: 图中狗的毛色是什么？                        │
│  A3: 图中的狗是金毛犬，毛色呈现温暖的金黄色...   │
│                                                 │
└─────────────────────────────────────────────────┘
```

#### 实现代码

```python
import openai

def generate_conversation(image_caption, objects, scene_description):
    """使用GPT-4生成多轮对话"""

    prompt = f"""Given the following image information:
    - Caption: {image_caption}
    - Objects detected: {objects}
    - Scene: {scene_description}

    Generate a multi-turn conversation about this image.
    Include:
    1. A question asking to describe the image
    2. A follow-up question about details
    3. A reasoning question

    Format as JSON:
    {{"conversations": [
        {{"from": "human", "value": "..."}},
        {{"from": "assistant", "value": "..."}},
        ...
    ]}}
    """

    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )

    return json.loads(response.choices[0].message.content)
```

### 方法2: 人工标注

适用于高质量benchmark和关键数据。

```
标注流程：
1. 展示图像给标注员
2. 标注员提出自然的问题
3. 标注员撰写详细回答
4. 质量审核
5. 多人交叉验证

成本高但质量最好
```

### 方法3: 任务数据转换

将现有的视觉任务数据转换为对话格式：

```python
# VQA数据转换
original = {
    "image": "coco_123.jpg",
    "question": "How many people are in the image?",
    "answer": "3"
}

converted = {
    "image": "coco_123.jpg",
    "conversations": [
        {"from": "human", "value": "<image>\nHow many people are in the image?"},
        {"from": "assistant", "value": "There are 3 people in the image."}
    ]
}
```

### LLaVA指令数据组成

```
LLaVA-Instruct-150K 数据分布：

├── 对话数据 (58K)
│   └── 多轮自然对话
│
├── 详细描述 (23K)
│   └── 长文本图像描述
│
├── 复杂推理 (77K)
│   └── 需要多步推理的问答
│
└── 总计: 158K 样本
```

---

## 5.3 数据质量过滤

### 完整过滤流程

```
原始网络数据 (噪声多)
        │
        ▼
┌─────────────────────────────────┐
│ Stage 1: 基础过滤               │
│ ├─ 图片可访问性                 │
│ ├─ 图片尺寸 > 256px            │
│ ├─ 文本长度 > 3 words          │
│ └─ 去除重复URL                  │
└─────────────────┬───────────────┘
                  ▼
┌─────────────────────────────────┐
│ Stage 2: CLIP分数过滤           │
│ ├─ 计算图文相似度               │
│ ├─ 阈值: 通常 > 0.25-0.30      │
│ └─ 过滤低相关性样本             │
└─────────────────┬───────────────┘
                  ▼
┌─────────────────────────────────┐
│ Stage 3: 文本质量过滤           │
│ ├─ 语言检测 (保留目标语言)      │
│ ├─ 去除HTML/特殊字符            │
│ ├─ 过滤广告/垃圾文本            │
│ └─ 文本去重 (SimHash/MinHash)   │
└─────────────────┬───────────────┘
                  ▼
┌─────────────────────────────────┐
│ Stage 4: 图像质量过滤           │
│ ├─ 分辨率检查                   │
│ ├─ 宽高比过滤 (去除极端比例)    │
│ ├─ 图像美学评分                 │
│ └─ 图像去重 (pHash)             │
└─────────────────┬───────────────┘
                  ▼
┌─────────────────────────────────┐
│ Stage 5: 安全过滤               │
│ ├─ NSFW检测                     │
│ ├─ 暴力内容检测                 │
│ ├─ 个人隐私信息过滤             │
│ └─ 版权内容识别                 │
└─────────────────┬───────────────┘
                  ▼
        高质量训练数据
```

### CLIP分数过滤

```python
import torch
from transformers import CLIPModel, CLIPProcessor

class CLIPFilter:
    def __init__(self, threshold=0.25):
        self.model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
        self.processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
        self.threshold = threshold

    def compute_score(self, image, text):
        """计算图文相似度分数"""
        inputs = self.processor(
            text=[text],
            images=image,
            return_tensors="pt",
            padding=True
        )

        with torch.no_grad():
            outputs = self.model(**inputs)
            # 归一化后计算余弦相似度
            image_embeds = outputs.image_embeds / outputs.image_embeds.norm(dim=-1, keepdim=True)
            text_embeds = outputs.text_embeds / outputs.text_embeds.norm(dim=-1, keepdim=True)
            score = (image_embeds @ text_embeds.T).item()

        return score

    def filter(self, image, text):
        """判断是否保留该样本"""
        score = self.compute_score(image, text)
        return score > self.threshold, score
```

### 文本质量过滤

```python
import re
import langdetect

class TextFilter:
    def __init__(self, target_lang='en', min_words=5, max_words=200):
        self.target_lang = target_lang
        self.min_words = min_words
        self.max_words = max_words

    def clean_text(self, text):
        """清理文本"""
        # 去除HTML标签
        text = re.sub(r'<[^>]+>', '', text)
        # 去除URL
        text = re.sub(r'http\S+', '', text)
        # 去除多余空格
        text = ' '.join(text.split())
        return text

    def filter(self, text):
        """判断文本是否合格"""
        text = self.clean_text(text)

        # 长度检查
        words = text.split()
        if len(words) < self.min_words or len(words) > self.max_words:
            return False, "length"

        # 语言检测
        try:
            lang = langdetect.detect(text)
            if lang != self.target_lang:
                return False, "language"
        except:
            return False, "language_detection_failed"

        # 垃圾文本检测
        spam_patterns = [
            r'click here',
            r'buy now',
            r'free download',
            r'\d{3}-\d{3}-\d{4}',  # 电话号码
        ]
        for pattern in spam_patterns:
            if re.search(pattern, text.lower()):
                return False, "spam"

        return True, "pass"
```

### 图像去重

```python
import imagehash
from PIL import Image

class ImageDeduplicator:
    def __init__(self, hash_size=16, threshold=5):
        self.hash_size = hash_size
        self.threshold = threshold
        self.seen_hashes = set()

    def compute_hash(self, image):
        """计算感知哈希"""
        if isinstance(image, str):
            image = Image.open(image)
        return imagehash.phash(image, hash_size=self.hash_size)

    def is_duplicate(self, image):
        """检查是否重复"""
        img_hash = self.compute_hash(image)

        for seen_hash in self.seen_hashes:
            if img_hash - seen_hash < self.threshold:
                return True

        self.seen_hashes.add(img_hash)
        return False
```

---

## 5.4 数据混合策略

### 预训练数据混合

```python
training_mix = {
    "laion_en": 0.4,      # 英文图文对
    "laion_zh": 0.1,      # 中文图文对
    "cc3m": 0.15,         # 高质量数据
    "cc12m": 0.15,        # 中等规模
    "synthetic": 0.2,     # 合成数据
}
```

### 指令微调数据混合

```python
instruction_mix = {
    "llava_instruct": 0.25,    # 通用对话
    "vqa_v2": 0.15,            # 视觉问答
    "ocr_data": 0.15,          # 文字识别
    "gqa": 0.10,               # 组合推理
    "text_caps": 0.10,         # 图像描述
    "share_gpt": 0.15,         # 纯文本对话
    "science_qa": 0.10,        # 科学问答
}
```

---

## 总结

| 数据类型 | 规模 | 用途 | 质量要求 |
|----------|------|------|----------|
| 预训练数据 | 亿级 | 学习对齐 | 中等 |
| 指令数据 | 十万-百万 | 学习指令遵循 | 高 |
| 评测数据 | 千-万级 | 能力评估 | 极高 |

数据工程的核心原则：
1. **质量优先**：高质量小数据 > 低质量大数据
2. **多样性**：任务多样、场景多样、语言多样
3. **平衡性**：各类数据比例合理
4. **持续迭代**：根据模型表现调整数据
